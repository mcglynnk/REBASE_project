---
title: "REBASE Project"
output: 
  html_notebook: 
    fig_caption: yes
    toc: yes
---

Project Headline: 
 “What can we learn about the bacterial species that restriction enzymes come 
 from?"
 
Four steps I'm going to show:

First,  how I got & cleaned the data,
 - Python: beautifulsoup
 - R: BacDiveR, BacDiveR.first (my modified version of the package), 
      tidyverse/dplyr

Second, exploratory analysis,
 - R: plotly, wordcloud2

Third, visualization,
 - R: leaflet, ggmap & Google geocoding API 

Fourth, Natural language processing
 - R: tidytext, ggplot2



# Getting & Cleaning Data

Move the restriction data from Python into R:
```{r}
library(tidyverse) #ggplot2, tibble, tidyr, readr, purrr, dplyr,stringr,forcats
library(magrittr) #gotta have that %>% pipe!

enz<-read.csv("enz.csv", header=T, sep=",", stringsAsFactors = F)
enz_tbl<-tibble::as_tibble(enz)  #easier to read!

# How many organisms?
length(enz_tbl$Org) #11,568 rows


#Add a new column to indicate with TRUE/FALSE whether the organism in that row 
#is a duplicate.
#Can then query data based on only non-duplicate (dup column == FALSE) rows
enz_tbl_dup<- tibble(value= enz_tbl$Org,
              dup= duplicated(value))

enz_tbl
```

Next, add data to this table on each bacterial species.
https://bacdive.dsmz.de/
BacDive - Bacterial Diversity Metadatabase (API via the BacDiveR package)
```{r message=FALSE}
library(BacDiveR.first)
#
# Source: https://github.com/TIBHannover/BacDiveR
# The BacDiveR package functions (bd_retrieve_taxon) take an organism name
# (or partial) as the search parameter and returns nested lists 
# containing all BacDive results that match the search/organism name.  
#
  # Two issues when trying to pass the function a list of organism names to
  # store in a data table: 
  # (1) Multiple results are returned for each list item (can't put in table)
  # (2) If a query fetches no results (or query is invalid format), an
  #   error is thrown and nothing is returned (leaving a gap in the results)
#
# Modified the package scripts and created the BacDiveR.first package:
#
# Modified scripts have identical names except with _first appended. Modified
# lines are marked with '## comment'.
#   util_aggregate_datasets: modified to return only one result per query
#   bd_retrieve_data: modified to return only one result per query, 
#                     modified to not 'stop' if an invalid search parameter is  
#                     used.
#                     modified to return search term if no results are returned
source("replace_na_null_functions.R")
```


Query BacDive to get bacteria info
```{r}
enz_tbl_data<- enz_tbl_dup %>% 
    # Queries BacDive (via the bd_retrieve_taxon_first function) to retrieve 
    # organism data (non-duplicates only).
    # Will only fetch data for the first unique of each value.
    #
    # Input: a tbl_df with 2 columns: 
    #  col.1: organism names, col.2: dup, containing TRUE or FALSE as to 
    #  whether the organism name is a duplicate in the table.
    #
    # Returns: a tbl_df with a new column
    #  containing (for first uniques) a nested list of retrieved BacDive data, 
    #  or (if organism was a duplicate) the organism name. 
    #    
      #add a new column to the input data table containing data
    { mutate(., 
        datax = apply(unname(.), 1, function(x) #apply to 1 = rows
            #Error handling
            tryCatch(ifelse(
                     x[2]==FALSE, yes=bd_retrieve_taxon_first(x[1]), no=x[1]),
            error = function(e) {print("error")}) ) 
        ) 
    } %>% 
    #mutate the new data column to remove one list level, replace above column
    { mutate(.,
        data =  unlist(datax, recursive = F)
     )   } %>% 
    #remove the original column
    select(., -datax)
```
```{r}
enz_tbl_data<- readRDS("enz_tbl_data.rds")
enz_tbl_data  #11,568 rows
```
```{r}
print(enz_tbl_data$data[[132]][3:4])
```


Extract organism data into new columns
```{r}
orginfo_tbl<- enz_tbl_data$data %>% {
  # Extracts values from nested data sets and makes a data table.
  #
  # Input: a data frame with a column ($data, here) containing nested datasets 
  # retrieved by bd_retrieve_taxon_first.
  #
  # Returns: a tbl_df containing (if index exists) values or 
  # (if index does not exist) NA. Replaces all NULL values with NA, then 
  # unnests.    
  tibble(
    #ID = names(.),
    organism = map(., possibly(~.x[["taxonomy_name"]][["strains"]][[
                                  "species"]][1] ,otherwise=NA)),
    sample_type = map(., possibly(~.x[["environment_sampling_isolation_source"
                        ]][["origin"]][["sample_type"]][1] ,otherwise=NA)),
    country = map(., possibly(~.x[["environment_sampling_isolation_source"]][[
                  "origin"]][["country"]][1] ,otherwise=NA)),
    geo = map(., possibly(~.x[["environment_sampling_isolation_source"]][[
             "origin"]][["geo_loc_name"]][1] ,otherwise=NA)), 
    tempr = map(., possibly(~.x[["culture_growth_condition"]][[
              "culture_temp"]][["temp"]][1] ,otherwise=NA)),
        ) } %>% 
  { tbl_df(sapply(., replace_null)) } %>% 
  unnest() %>% 
  bind_cols(.,dplyr::select(enz_tbl_data,-data))
```
```{r paged.print=FALSE}
orginfo_tbl<- readRDS("orginfo_tbl.rds")
orginfo_tbl_full<-readRDS("orginfo_tbl_full.rds")
orginfo_tbl %>% 
  dplyr::select(value, sample_type, tempr, geo, country) 
```

Combine the two tables: restriction enzyme info and bacteria info:

```{r}
#Merge orginfo_tbl_full (bacteria data) with enz_tbl (restriction enzyme data)

rebase_tbl<-bind_cols(enz_tbl, orginfo_tbl_full)

rebase_tbl_unique<- bind_cols(enz_tbl, orginfo_tbl)

#Check that combine was correct across rows
# rebase_tbl %>% 
#   mutate(.,
#          check = .['Org']==.['value']) %>%
#   select(., check) %>% {
#   data.frame(Org_matches_value = length(which(.$check==TRUE)),
#              Org_doesnotmatch_value = length(which(.$check==FALSE))) }

```

Final Cleanup
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
# Final cleanup ----------------------------------------------------------

#Remove id columns, paste (city, country) into one column for lat/lon retrieval
rebase_tbl<- rebase_tbl %>%
  dplyr::select(., -c(id, dup, value, organism)) %>%  #remove columns
  mutate(., geo = paste(geo, country, sep = ", ")) %>% 
  dplyr::select(., -c(country, Year)) %>% #remove country
  { tbl_df(sapply(., replace_na)) } %>% 
  mutate_at(., "tempr", as.numeric)

rebase_tbl_unique<- rebase_tbl_unique %>%
  dplyr::select(., -c(dup, value, organism)) %>% 
  mutate(., geo = paste(geo, country, sep = ", ")) %>% 
  dplyr::select(., -c(country, Year)) %>% #remove country
  { tbl_df(sapply(., replace_na)) } %>% 
  mutate_at(., "tempr", as.numeric) 

#Cases with a complete location:
rebase_tbl_complete<- rebase_tbl[which(rebase_tbl$geo != 'NA'),]

rebase_locs<- readRDS("rebase_locs.rds") %>% mutate_at(., "tempr", as.numeric)
rebase_tbl
```


# Data Exploration

```{r message=FALSE, warning=FALSE, paged.print=TRUE}
#Which organism produced the most restriction enzymes?
library(wordcloud2)
orgscloud<-rebase_tbl %>% 
  count(Org, sort = TRUE) %>% 
  wordcloud2(., size = 0.3)
orgscloud

#Visualize summary data
library(plotly)

plot_ly(
  labels = c("total restriction enzymes", "unique organisms",
             "complete location values", "sample types"
             ),
  parents = c("", "","unique organisms", "unique organisms" ),
  values = c(nrow(rebase_tbl), length(unique(rebase_tbl$Org)),
             length(which(!is.na(rebase_locs$lon))),   
             length(which(!is.na(rebase_tbl_unique$sample_type)))
             ),
  type = 'sunburst',
  sizes = c(100,80,10)
)


```


# Visualization

Get latitude & longitude values, and put bacterial species' sources
on a world map!

```{r message=FALSE, warning=FALSE}
library(leaflet) # Mapping
library(ggmap) # To query lat/lon with Google geocoding API
```

Convert the geo variable to latitude and longitude
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
#Setup
#library(rgdal)
library(htmltools)
options(stringsAsFactors = FALSE)

#Set API key from google cloud
source('~/ggmap key.R')
ggmap::register_google(key = key)

#Get latitude and longitude
#rebase_tbl<- readRDS("rebase_tbl.rds")
rebase_tbl_complete<- readRDS("rebase_tbl_complete.rds")

#--------
# Get latitude and longitude using ggmap (adds 2 new columns with lat and lon)
#--------
#rebase_locs<-mutate_geocode(rebase_tbl_complete, geo)

#saveRDS(rebase_locs, file="rebase_locs.rds")
rebase_locs<- readRDS("rebase_locs.rds") %>% mutate_at(., "tempr", as.numeric)

rebase_locs %>% dplyr::select(REnz, Org, sample_type, geo, lon, lat) 
```

Setting up the map for leaflet:
```{r message=FALSE, warning=FALSE}
# World map shapefile ----------------------------------------------------
library(raster)
#source
#http://thematicmapping.org/downloads/world_borders.php

countries<- shapefile("TM_WORLD_BORDERS-0.3/TM_WORLD_BORDERS-0.3.shp")

# Add layers data --------------------------------------------------------

#Research data
#source: https://www.scimagojr.com/countryrank.php
source("res.R")

#Volcano data
#source: https://earthworks.stanford.edu/catalog/harvard-glb-volc
source("volc.R")

# Prepare research_data and the shapefile -------------------------------

library(tigris)
research_data_joined<- geo_join(countries, research_data, "NAME", "country")


# Leaflet colors ---------------------------------------------------------

#Publications map overlay colors
pal<- colorNumeric (
  #palette = colorRamp(c("#18639e", "#b7d4eb"), interpolate="spline"), 
  palette = c('#1C3CBA', '#4359BC', '#5A6DC5', '#7181CE',
              '#8896D7', '#9FABDF', '#B7C0E7',
              '#CFD5EF'),
  domain = research_data_joined$citable_documents,
  reverse = T)

#Growth temperature colors
palgrowth<- colorNumeric (
  palette = c('#b2182b','#b92f40', '#da6f5e', '#E88D66',
               '#FFAB7A','#BADDEF','#4393c3'),
  domain = rebase_locs$tempr, 
  na.color = '#cccccc',
  reverse = T)

# Map labels functions --------------------------------------------------------

#Allow newline in each label, bold 'Restriction Enzyme' and 'Sample'
#   *Use map2 to apply this function
twolabels<- function(enz, samplet) {
  htmltools::HTML(
    sprintf(
    "<b>Restriction Enzyme:</b> %s<br/>
     <b>Sample:</b> %s",
    enz, samplet)
    )
}

#Same as above, but with 3 labels for the temperature map layer
#   *Must use pmap to apply this function
threelabels<- function(enz, samplet, temp) {
  htmltools::HTML(
    sprintf(
      "<b>Restriction Enzyme:</b> %s<br/>
       <b>Sample:</b> %s<br/>
       <b>Temp:</b> %s°C
      ",
      enz, samplet, temp)
  )
}

```

Leaflet map!
```{r}
# Rebase leaflet map -----------------------------------------------------

#Making the map!
library(parallel)
options(mc.cores = 2L)

rebase_map<- leaflet(rebase_locs) %>%
  ## Set view settings
  setMaxBounds( lng1 = -180 , 
                lat1 = 85,
                lng2 = 180,
                lat2 = -85 ) %>% 
  setView(lng = 0, lat = 0, zoom = 1) %>% 
  addProviderTiles("CartoDB.Positron", group = "Base map") %>% 
  
  ## Overlay groups
  # Organisms-only layer
  addCircles(lng = ~lon, lat = ~lat, 
             label = ~map2(rebase_locs$REnz, 
                           rebase_locs$sample_type, twolabels), 
             group = "Organisms"
              ) %>%
  
  # Layer to color map by research articles, with organism points added
  addPolygons(data = research_data_joined, stroke = FALSE,
              smoothFactor = 0.5, fillOpacity = 0.8,
              color = ~pal(research_data_joined$citable_documents),
              group = "Research Articles per Country") %>% 
  addCircles(data = rebase_locs, lng = ~lon, lat = ~lat, 
             #label = ~map2(rebase_locs$REnz, 
                            #rebase_locs$sample_type, labels),
             color = "#000000", radius = 5,
             group = "Research Articles per Country") %>%
  addLegend("bottomright", pal = pal, 
            values = research_data_joined$citable_documents,
            title = "Total Research Publications 1996-2018",
            opacity = 0.8, 
            group = "Research Articles per Country") %>%
  
  # Layer for volcanic data
  addCircles(data = volcano_data_sh, 
             lng = ~volcano_data_sh$LON, lat = ~volcano_data_sh$LAT, 
             stroke = F, opacity = 0.3,
             dashArray = T,
             fillOpacity = 0.3,
             radius = 30,
             color = '#C1539B',
             group = "Volcanic Activity") %>% 
  
  # Layer adding organism points colored by growth temperature
  addCircles(lng = ~lon, lat = ~lat,
             label = ~pmap(list(rebase_locs$REnz, 
                           rebase_locs$sample_type,
                           rebase_locs$tempr),
                           threelabels),
             group = "Organisms by growth temperature",
             color = ~palgrowth(tempr)) %>% 
  addLegend("bottomright", pal = palgrowth, 
            values = rebase_locs$tempr,
            title = "Growth temperature",
            labFormat = labelFormat(suffix = "°C"),
            opacity = 1, 
            group = "Organisms by growth temperature") %>%
 
  
  ## Layers control
  addLayersControl(
    baseGroups = c("Base map"),
    overlayGroups = c("Organisms", "Research Articles per Country",
                      "Organisms by growth temperature",
                      "Volcanic Activity"),
    options = layersControlOptions(collapsed = FALSE)
    ) %>% 
    hideGroup(c("Research Articles per Country", 
                "Organisms by growth temperature","Volcanic Activity"))

  
rebase_map


# end map ----------------------------------------------------------------

```

# NLP

Dive into the sample_type column:
What can we learn about the types of samples these organisms came from?

Setup
```{r}
library(tidytext) #text mining
library(topicmodels)
source("replace_na_null_functions.R")
```

Data Conditioning
```{r}
#Sample_type values to lowercase
rebase_tbl_unique$sample_type<- sapply(rebase_tbl_unique$sample_type, 
                                 tolower)

rebase_tbl_unique2<-rebase_tbl_unique %>% 
  dplyr::select(-c(Rtype, tempr, geo)) %>% 
  { tbl_df(sapply(., replace_na)) }

#Remove punctuation, white space, and species names within sample_type 
rebase_tbl_unique2$sample_type<- rebase_tbl_unique2$sample_type %>% 
  {sapply(., function(x) { gsub("[[:punct:]]", replacement = " ", x) } )} %>% 
  trimws() %>% 
  {sapply(., function(x) { 
            gsub("([i]  \\w+ \\w+  [i])", 
                 replacement = "", x) } ) } %>% 
  {sapply(., function(x) { gsub("[[:punct:]]", replacement = " ", x) } )} %>% 
  trimws()

```

Tokenization, remove stop words, and tokenization with n-grams
```{r}
#tokenize normally
rebase_tbl_total_words<- rebase_tbl_unique2 %>% 
  mutate('sample' = sample_type) %>% 
  unnest_tokens(word, sample_type) %>% #tokenize
  anti_join(stop_words, by = "word") %>%  #remove stop words
  filter(nchar(word) > 2) %>% #filter out NA values
  count(word, sort = TRUE)
rebase_tbl_total_words

# Bar graph for top 10 total tokenized words
rebase_tbl_total_words[1:10,] %>% 
  ggplot() +
  geom_col(aes(x= reorder(word, -n), y=n)) +
  labs(title = "Top 10 Sample Words", x="Word", y="Number") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5), 
        axis.text.x = element_text(angle=50,hjust=1,vjust = 1.2, size = 12) ) 

```


Tokenization with n-grams:
What are the most common two-word terms?
```{r}
#tokenize with n-grams
library(tidytext)

# Tokenize with n-grams
rebase_tbl_total_bigrams<- rebase_tbl_unique2 %>% 
  mutate('sample' = sample_type) %>% 
  filter(nchar(sample_type) > 2) %>% #filter out NA values
  unnest_tokens(bigrams, sample_type, token = "ngrams", n=2)

# Remove stop words and unigrams, count total bigrams
rebase_tbl_total_bigrams<- rebase_tbl_total_bigrams %>% 
  separate(bigrams, c("word1", "word2"), sep = " ") %>% 
  filter(!word1 %in% stop_words$word) %>%  #remove stop words
  filter(!word2 %in% stop_words$word) %>%  #remove stop words
  filter(!is.na(word1) & !is.na(word2)) %>% #remove NA
  unite(bigrams, word1, word2, sep = " ") %>% #join back together
  dplyr::select(Org, sample, bigrams) %>% 
  count(bigrams, sort = TRUE)

# Bar graph for top 10 total tokenized bigrams
geomcol_bigrams<- rebase_tbl_total_bigrams[1:10,] %>% 
  ggplot() +
  geom_col(aes(x= reorder(bigrams, -n), y=n), fill="tomato1") +
  labs(title = "Top 10 Sample Bigrams", x="Bigram", y="Number") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5), 
        axis.text.x = element_text(angle=50,hjust=1,vjust = 1.1, size = 12),
        ) 

geomcol_bigrams
```


What are the most common two-word terms within categories like water and soil?
```{r}
# Ocean/sea samples bar graph
sea_words<- c("sea","ocean","water","spring","pond", "hydrothermal", 
              "lake","marine","freshwater","seawater","geothermal") #keywords

geomcol_bigrams_sea<- rebase_tbl_total_bigrams %>% 
  separate(bigrams, c("word1", "word2"), sep = " ") %>% 
  filter(., word1 %in% sea_words | word2 %in% sea_words) %>% 
  unite(bigrams, word1, word2, sep = " ") %>% 
  slice(., 1:10) %>% 
  ggplot() +
  geom_col(aes(x= reorder(bigrams, -n), y=n), fill="turquoise") +
  labs(title = "Top 10 Water Bigrams", x="Bigram", y="Number") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5), 
        axis.text.x = element_text(angle=50,hjust=1,vjust = 1.1, size = 12),
  ) 

# Soil/sediment samples bar graph
soil_words<- c("soil","mud","sediment","swamp","sewage","sludge","mine",
               "wood","field","compost") #keywords

geomcol_bigrams_soil<- rebase_tbl_total_bigrams %>% 
  separate(bigrams, c("word1", "word2"), sep = " ") %>% 
  filter(., word1 %in% soil_words | word2 %in% soil_words) %>% 
  unite(bigrams, word1, word2, sep = " ") %>% 
  slice(., 1:10) %>% 
  ggplot() +
  geom_col(aes(x= reorder(bigrams, -n), y=n), fill="khaki") +
  labs(title = "Top 10 Soil Bigrams", x="Bigram", y="Number") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5), 
        axis.text.x = element_text(angle=50,hjust=1,vjust = 1.1, size = 12),
  )
```

Look at these graphs together:
```{r}
geomcol_bigrams_soil
geomcol_bigrams_sea
geomcol_bigrams

```


# ~ The End ~

Potential use cases:
 - Public interest & curiosity!
 - (For the leaflet map) R Shiny web app for restriction enzyme suppliers
   to engage with customers
 
 How these skills can be used for future projects & employers!
 - Leaflet mapping for epidemiology studies
 - The NLP functions & analyses I used here could be useful for extracting
   data from electronic medical records
 
 










































































LDA Topic modeling using the topicmodels package

LDA rests on the assumption that each document is going to have some 
subset of topics in it, and that each topic is associated with a certain subset
of words.

```{r}
library(topicmodels)

# Make another table in the format for dtm casting
rebase_tbl_wordcount<- rebase_tbl_unique2 %>% 
  mutate('sample' = sample_type) %>% 
  unnest_tokens(word, sample_type) %>% 
  anti_join(stop_words, by = "word") %>% 
  distinct() %>% 
  filter(nchar(word) > 2) %>%
  count(sample, word, sort = TRUE)

# Cast a one-token-per-row table into a DocumentTermMatrix with 
# tidytext's cast_dtm:

rebase_dtm<- rebase_tbl_wordcount %>%
             cast_dtm(sample, word, n)

#rebase_dtm
```

LDA - first determine the best number of topics using the ldatuning package
```{r}
#ldatuning
library(ldatuning)

rebaseLDAtopic_test <- FindTopicsNumber(
  rebase_dtm,
  topics = seq(from = 2, to = 25, by = 1),
  metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"),
  method = "Gibbs",
  control = list(seed = 1234),
  mc.cores = 2L,
  verbose = T
)

```

